{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "17f3eea2",
      "metadata": {
        "id": "17f3eea2"
      },
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f4e7712f",
      "metadata": {
        "id": "f4e7712f",
        "outputId": "eb2f45b1-2904-48fa-86d1-33b6d4f786a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Royal_data.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c4bace715b4b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Royal_data.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mroyal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroyal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Royal_data.txt'"
          ]
        }
      ],
      "source": [
        "file = open('Royal_data.txt', 'r')\n",
        "royal_data = file.readlines()\n",
        "print(royal_data)\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1369aa51",
      "metadata": {
        "id": "1369aa51"
      },
      "source": [
        "### Removing '\\n' from the end of every sentence and convert the sentence into lowercase   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "88af9298",
      "metadata": {
        "id": "88af9298",
        "outputId": "05c54074-b8f5-4520-fa14-2b8a8f37c227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'royal_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c93b30cef1a0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroyal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mroyal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroyal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroyal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'royal_data' is not defined"
          ]
        }
      ],
      "source": [
        "for i in range(len(royal_data)):\n",
        "    royal_data[i] = royal_data[i].lower().replace('\\n', '')\n",
        "\n",
        "print(royal_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03c1aec2",
      "metadata": {
        "id": "03c1aec2"
      },
      "source": [
        "### Removing stop words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "236da810",
      "metadata": {
        "id": "236da810"
      },
      "outputs": [],
      "source": [
        "stopwords = ['the', 'is', 'will', 'be', 'a', 'only', 'can', 'their', 'now', 'and', 'at', 'it']\n",
        "\n",
        "filtered_data = []\n",
        "for sent in royal_data:\n",
        "    temp = []\n",
        "    for word in sent.split():\n",
        "        if word not in stopwords:\n",
        "            temp.append(word)\n",
        "    filtered_data.append(temp)\n",
        "\n",
        "print(filtered_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c060ff9",
      "metadata": {
        "id": "9c060ff9"
      },
      "source": [
        "### Creating bigrams\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feb52dc7",
      "metadata": {
        "id": "feb52dc7"
      },
      "outputs": [],
      "source": [
        "bigrams = []\n",
        "for words_list in filtered_data:\n",
        "    for i in range(len(words_list) - 1):\n",
        "        for j in range(i+1, len(words_list)):\n",
        "            bigrams.append([words_list[i], words_list[j]])\n",
        "            bigrams.append([words_list[j], words_list[i]])\n",
        "\n",
        "\n",
        "print(bigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9c73a57",
      "metadata": {
        "id": "a9c73a57"
      },
      "source": [
        "### Getting a list of unique words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20547a7c",
      "metadata": {
        "id": "20547a7c"
      },
      "outputs": [],
      "source": [
        "all_words = []\n",
        "for bi in bigrams:\n",
        "    all_words.extend(bi)\n",
        "\n",
        "all_words = list(set(all_words))\n",
        "all_words.sort()\n",
        "\n",
        "print(all_words)\n",
        "print(\"Total number of unique words are:\", len(all_words))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e20adfa",
      "metadata": {
        "id": "2e20adfa"
      },
      "source": [
        "### Creating dictionary of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e8da645",
      "metadata": {
        "id": "5e8da645"
      },
      "outputs": [],
      "source": [
        "words_dict = {}\n",
        "\n",
        "counter = 0\n",
        "for word in all_words:\n",
        "    words_dict[word] = counter\n",
        "    counter += 1\n",
        "\n",
        "print(words_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f911c7d",
      "metadata": {
        "id": "3f911c7d"
      },
      "source": [
        "### Performing one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7062308d",
      "metadata": {
        "id": "7062308d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "onehot_data = np.zeros((len(all_words), len(all_words)))\n",
        "\n",
        "for i in range(len(all_words)):\n",
        "    onehot_data[i][i] = 1\n",
        "\n",
        "onehot_dict = {}\n",
        "counter = 0\n",
        "for word in all_words:\n",
        "    onehot_dict[word] = onehot_data[counter]\n",
        "    counter += 1\n",
        "\n",
        "for word in onehot_dict:\n",
        "    print(word, \":\", onehot_dict[word])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a6fe9e5",
      "metadata": {
        "id": "0a6fe9e5"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "for bi in bigrams:\n",
        "    print(bi)\n",
        "    X.append(onehot_dict[bi[0]])\n",
        "    Y.append(onehot_dict[bi[1]])\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "rzQwdJARRIlL",
        "outputId": "15dc7b8a-32e6-405a-aee9-536343567662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "id": "rzQwdJARRIlL",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b5fec669aca1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "id": "6uM5nA2cKriQ"
      },
      "id": "6uM5nA2cKriQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d218441d",
      "metadata": {
        "id": "d218441d"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91f1fa31",
      "metadata": {
        "id": "91f1fa31"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "embed_size = 2\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(embed_size, activation='linear'),\n",
        "    Dense(Y.shape[1], activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3796ca1b",
      "metadata": {
        "id": "3796ca1b"
      },
      "outputs": [],
      "source": [
        "model.fit(X, Y, epochs = 1000, batch_size = 256, verbose = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e9d8ebe",
      "metadata": {
        "id": "2e9d8ebe"
      },
      "outputs": [],
      "source": [
        "weights = model.get_weights()[0]\n",
        "\n",
        "word_embeddings = {}\n",
        "for word in all_words:\n",
        "    word_embeddings[word] = weights[words_dict[word]]\n",
        "\n",
        "# print(word_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95cf5e2d",
      "metadata": {
        "id": "95cf5e2d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.figure(figsize = (10, 10))\n",
        "for word in list(words_dict.keys()):\n",
        "    coord = word_embeddings.get(word)\n",
        "    plt.scatter(coord[0], coord[1])\n",
        "    plt.annotate(word, (coord[0], coord[1]))\n",
        "\n",
        "plt.savefig('img.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[26][None,]"
      ],
      "metadata": {
        "id": "FMz0HCb0FtIo"
      },
      "id": "FMz0HCb0FtIo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "fc9-giM1IA0s"
      },
      "id": "fc9-giM1IA0s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e116aadf",
      "metadata": {
        "id": "e116aadf"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "x=model.predict(onehot_dict['queen'].reshape(1,-1))\n",
        "print(x)\n",
        "print(numpy.max(x))\n",
        "all_words[numpy.argmax(x)]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "f06e3119828c145c4028f0fee76387e74b42caa79bccb80b4ba64fe213bb9e06"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}